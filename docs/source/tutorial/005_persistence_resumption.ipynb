{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f557c4",
   "metadata": {},
   "source": [
    "# Tutorial 005: Experiment Persistence and Resumption\n",
    "\n",
    "## Overview\n",
    "\n",
    "One of EarlySign's key enterprise features is the ability to **pause and resume experiments** seamlessly. This is crucial for:\n",
    "\n",
    "- **Long-running experiments** that span weeks or months\n",
    "- **System maintenance** or upgrades during experiments  \n",
    "- **Regulatory compliance** requiring audit trails\n",
    "- **Disaster recovery** scenarios\n",
    "- **Multi-team handoffs** where different analysts continue experiments\n",
    "\n",
    "This tutorial demonstrates how to:\n",
    "1. **Persist experiment state** in the ledger\n",
    "2. **Resume experiments** from stored data\n",
    "3. **Reconstruct experiment modules** from ledger history\n",
    "4. **Handle configuration changes** during resumption\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Event Sourcing Foundation\n",
    "EarlySign's event sourcing architecture makes persistence natural:\n",
    "- **Immutable events**: All experiment state captured as events\n",
    "- **Complete history**: Every decision and computation recorded\n",
    "- **Reproducible state**: Any point in time can be reconstructed\n",
    "- **Ledger as source of truth**: No external state dependencies\n",
    "\n",
    "### Resumption Patterns\n",
    "```python\n",
    "# Pattern 1: Simple resumption (same configuration)\n",
    "experiment = MyExperiment.from_ledger(ledger, experiment_id)\n",
    "\n",
    "# Pattern 2: Configuration evolution (updated parameters)  \n",
    "experiment = MyExperiment.from_ledger(ledger, experiment_id, new_config)\n",
    "\n",
    "# Pattern 3: Cross-platform resumption (different backend)\n",
    "old_ledger = PolarsLedger.load(\"experiment_backup.parquet\")\n",
    "new_ledger = DatabaseLedger(connection_string)\n",
    "experiment = MyExperiment.migrate(old_ledger, new_ledger, experiment_id)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa09c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# EarlySign framework\n",
    "from earlysign.api.ab_test import (\n",
    "    ab_test_with_guardrails,\n",
    "    GuardrailConfig,\n",
    "    ABTestExperiment,\n",
    ")\n",
    "from earlysign.runtime import SequentialRunner\n",
    "from earlysign.backends.polars.ledger import PolarsLedger\n",
    "from earlysign.methods.group_sequential.adaptive import AdaptiveInfoTime\n",
    "\n",
    "print(\"âœ… EarlySign framework loaded\")\n",
    "print(\"ðŸ“š Tutorial 005: Experiment Persistence and Resumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ff035",
   "metadata": {},
   "source": [
    "## Scenario: Multi-Day A/B Test with System Maintenance\n",
    "\n",
    "We'll simulate a realistic scenario:\n",
    "1. **Day 1**: Start an A/B test for homepage redesign\n",
    "2. **Day 2**: Add more data, system needs maintenance â†’ **pause experiment**  \n",
    "3. **Day 3**: Resume after maintenance, continue adding data\n",
    "4. **Day 4**: Complete analysis and make decision\n",
    "\n",
    "This demonstrates the **real-world workflow** where experiments span multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99249e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Day 1: Initial Experiment Setup\n",
    "\n",
    "# Create persistent ledger (file-based for this demo)\n",
    "ledger_path = Path(\"homepage_experiment.parquet\")\n",
    "ledger = PolarsLedger()\n",
    "\n",
    "# Configure A/B test with guardrails\n",
    "guardrails = [\n",
    "    GuardrailConfig(name=\"bounce_rate\", alpha=0.025, method=\"safe_test\"),\n",
    "    GuardrailConfig(name=\"load_time\", alpha=0.025, method=\"safe_test\"),\n",
    "]\n",
    "\n",
    "# Create experiment\n",
    "experiment = ab_test_with_guardrails(\n",
    "    experiment_id=\"exp#homepage_redesign_2025\",\n",
    "    primary_alpha=0.05,\n",
    "    guardrails=guardrails,\n",
    "    looks=5,\n",
    "    adaptive_info=True,\n",
    "    target_n_per_arm=2000,\n",
    ")\n",
    "\n",
    "# Create runner and setup\n",
    "runner = SequentialRunner(experiment, ledger)\n",
    "runner.setup()\n",
    "\n",
    "print(f\"âœ… Day 1: Experiment '{experiment.experiment_id}' started\")\n",
    "print(f\"Primary endpoint: Î± = {experiment.primary_alpha}\")\n",
    "print(f\"Guardrails: {[g.name for g in experiment.guardrails]}\")\n",
    "print(f\"Target sample size: {experiment.target_n_per_arm} per arm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 1: Collect initial data (500 users per arm)\n",
    "np.random.seed(2025)\n",
    "\n",
    "# Simulate A/B test data - control vs. new homepage\n",
    "n_day1 = 500\n",
    "\n",
    "# Control group (A): current homepage, 12% conversion\n",
    "conversions_A_day1 = np.random.binomial(n_day1, 0.12)\n",
    "# Treatment group (B): new homepage, 14% conversion (2pp lift)\n",
    "conversions_B_day1 = np.random.binomial(n_day1, 0.14)\n",
    "\n",
    "# Add observations to ledger\n",
    "runner.add_observations(\n",
    "    nA=n_day1,\n",
    "    nB=n_day1,\n",
    "    mA=conversions_A_day1,\n",
    "    mB=conversions_B_day1,\n",
    "    # Guardrail data (bounce rate - lower is better)\n",
    "    bounce_nA=n_day1,\n",
    "    bounce_nB=n_day1,\n",
    "    bounce_mA=int(n_day1 * 0.35),\n",
    "    bounce_mB=int(n_day1 * 0.33),  # Slight improvement\n",
    "    # Load time data (proportion of slow loads)\n",
    "    load_nA=n_day1,\n",
    "    load_nB=n_day1,\n",
    "    load_mA=int(n_day1 * 0.08),\n",
    "    load_mB=int(n_day1 * 0.09),  # Slight degradation\n",
    ")\n",
    "\n",
    "# Analyze Day 1 results\n",
    "result_day1 = runner.analyze()\n",
    "\n",
    "print(f\"ðŸ“Š Day 1 Results:\")\n",
    "print(f\"Sample size: {n_day1} per arm\")\n",
    "print(\n",
    "    f\"Control conversion: {conversions_A_day1}/{n_day1} = {conversions_A_day1/n_day1:.1%}\"\n",
    ")\n",
    "print(\n",
    "    f\"Treatment conversion: {conversions_B_day1}/{n_day1} = {conversions_B_day1/n_day1:.1%}\"\n",
    ")\n",
    "print(f\"Should stop: {result_day1.should_stop}\")\n",
    "print(f\"Decision: {result_day1.primary_decision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”„ PERSISTENCE: Save experiment state to disk\n",
    "# This is the key step for experiment persistence!\n",
    "\n",
    "# Save ledger to persistent storage\n",
    "ledger.save(ledger_path)\n",
    "\n",
    "# Extract experiment configuration for resumption\n",
    "experiment_config = {\n",
    "    \"experiment_id\": experiment.experiment_id,\n",
    "    \"primary_alpha\": experiment.primary_alpha,\n",
    "    \"guardrails\": [\n",
    "        {\n",
    "            \"name\": g.name,\n",
    "            \"alpha\": g.alpha,\n",
    "            \"method\": g.method,\n",
    "            \"alpha_prior\": g.alpha_prior,\n",
    "            \"beta_prior\": g.beta_prior,\n",
    "        }\n",
    "        for g in experiment.guardrails\n",
    "    ],\n",
    "    \"looks\": experiment.looks,\n",
    "    \"spending\": experiment.spending,\n",
    "    \"target_n_per_arm\": experiment.target_n_per_arm,\n",
    "    \"adaptive_info\": experiment.adaptive_info,\n",
    "}\n",
    "\n",
    "print(\"ðŸ’¾ Day 1: Experiment state persisted\")\n",
    "print(f\"Ledger saved to: {ledger_path}\")\n",
    "print(f\"Configuration: {len(experiment_config)} parameters saved\")\n",
    "print(\"ðŸŒ™ End of Day 1 - System going down for maintenance...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b05f7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Day 3: Resumption After Maintenance\n",
    "\n",
    "**Scenario**: System maintenance is complete. A new analyst needs to continue the experiment.\n",
    "They only have:\n",
    "- ðŸ“ The persisted ledger file\n",
    "- ðŸ“‹ The experiment configuration  \n",
    "- ðŸŽ¯ Knowledge that the experiment should continue\n",
    "\n",
    "**Key Question**: How easily can they reconstruct the full experiment state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5719f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”„ RESUMPTION: Reconstruct experiment from persistent state\n",
    "# Simulate a completely fresh Python session\n",
    "\n",
    "# Clear all variables (simulate new session)\n",
    "del runner, experiment, ledger, result_day1\n",
    "\n",
    "# Step 1: Load ledger from disk\n",
    "print(\"ðŸ”„ Day 3: Resuming experiment after maintenance...\")\n",
    "resumed_ledger = PolarsLedger.load(ledger_path)\n",
    "\n",
    "print(f\"âœ… Ledger loaded: {resumed_ledger.count_events()} events\")\n",
    "\n",
    "# Step 2: Reconstruct experiment configuration\n",
    "# In production, this would come from a config management system\n",
    "resumed_guardrails = [\n",
    "    GuardrailConfig(**config) for config in experiment_config[\"guardrails\"]\n",
    "]\n",
    "\n",
    "# Step 3: Recreate experiment module\n",
    "resumed_experiment = ab_test_with_guardrails(\n",
    "    experiment_id=experiment_config[\"experiment_id\"],\n",
    "    primary_alpha=experiment_config[\"primary_alpha\"],\n",
    "    guardrails=resumed_guardrails,\n",
    "    looks=experiment_config[\"looks\"],\n",
    "    adaptive_info=experiment_config[\"adaptive_info\"],\n",
    "    target_n_per_arm=experiment_config[\"target_n_per_arm\"],\n",
    ")\n",
    "\n",
    "# Step 4: Recreate runner with resumed state\n",
    "resumed_runner = SequentialRunner(resumed_experiment, resumed_ledger)\n",
    "\n",
    "# IMPORTANT: Re-setup to reconstruct internal component state from ledger events\n",
    "resumed_runner.setup()\n",
    "\n",
    "print(f\"âœ… Experiment '{resumed_experiment.experiment_id}' resumed\")\n",
    "print(f\"State reconstructed from {resumed_ledger.count_events()} ledger events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that resumed state matches the original\n",
    "resumed_result = resumed_runner.analyze()\n",
    "\n",
    "print(\"ðŸ” State Verification:\")\n",
    "print(f\"Experiment ID: {resumed_experiment.experiment_id}\")\n",
    "print(f\"Primary alpha: {resumed_experiment.primary_alpha}\")\n",
    "print(f\"Guardrails: {[g.name for g in resumed_experiment.guardrails]}\")\n",
    "print(f\"Current decision: {resumed_result.primary_decision}\")\n",
    "print(f\"Should stop: {resumed_result.should_stop}\")\n",
    "\n",
    "# Show that we can access the complete experiment history\n",
    "print(f\"\\nðŸ“š Complete Event History Available:\")\n",
    "all_events = resumed_ledger.query_events()\n",
    "event_summary = (\n",
    "    all_events.group_by([\"namespace\", \"kind\"])\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"namespace\", \"kind\")\n",
    ")\n",
    "print(event_summary)\n",
    "\n",
    "print(f\"\\nâœ… Experiment state perfectly reconstructed!\")\n",
    "print(f\"ðŸ‘ Ready to continue with Day 3 data collection...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3: Continue experiment with more data\n",
    "print(\"ðŸ“ˆ Day 3: Adding more data to resumed experiment...\")\n",
    "\n",
    "# Add Day 3 data (700 more users per arm)\n",
    "n_day3 = 700\n",
    "\n",
    "# Continue the trend - treatment still performing better\n",
    "conversions_A_day3 = np.random.binomial(n_day3, 0.12)\n",
    "conversions_B_day3 = np.random.binomial(n_day3, 0.145)  # Slightly stronger effect\n",
    "\n",
    "# Add to the RESUMED experiment\n",
    "resumed_runner.add_observations(\n",
    "    nA=n_day3,\n",
    "    nB=n_day3,\n",
    "    mA=conversions_A_day3,\n",
    "    mB=conversions_B_day3,\n",
    "    # Guardrail data\n",
    "    bounce_nA=n_day3,\n",
    "    bounce_nB=n_day3,\n",
    "    bounce_mA=int(n_day3 * 0.34),\n",
    "    bounce_mB=int(n_day3 * 0.32),\n",
    "    load_nA=n_day3,\n",
    "    load_nB=n_day3,\n",
    "    load_mA=int(n_day3 * 0.08),\n",
    "    load_mB=int(n_day3 * 0.095),\n",
    ")\n",
    "\n",
    "# Analyze cumulative results (Day 1 + Day 3)\n",
    "day3_result = resumed_runner.analyze()\n",
    "\n",
    "print(f\"ðŸ“Š Day 3 Cumulative Results:\")\n",
    "print(f\"Total sample size: {n_day1 + n_day3} per arm\")\n",
    "print(f\"Should stop: {day3_result.should_stop}\")\n",
    "print(f\"Decision: {day3_result.primary_decision}\")\n",
    "print(f\"Stop reason: {day3_result.stop_reason}\")\n",
    "\n",
    "# The beauty: All history is preserved and cumulative analysis works perfectly!\n",
    "total_events = resumed_ledger.count_events()\n",
    "print(f\"\\nâœ… Total events in ledger: {total_events}\")\n",
    "print(f\"ðŸŽ¯ Seamless continuation across system restart!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94287d7e",
   "metadata": {},
   "source": [
    "## Enterprise Resumption Patterns\n",
    "\n",
    "The basic pattern we demonstrated can be enhanced for enterprise use:\n",
    "\n",
    "### 1. **Configuration Management Integration**\n",
    "```python  \n",
    "# Instead of manual config dicts, integrate with enterprise systems\n",
    "from my_company.config_service import ExperimentConfigManager\n",
    "\n",
    "config_manager = ExperimentConfigManager()\n",
    "experiment_config = config_manager.get_config(experiment_id)\n",
    "experiment = ab_test_with_guardrails(**experiment_config)\n",
    "```\n",
    "\n",
    "### 2. **Cross-Platform Migration**\n",
    "```python\n",
    "# Move experiments between different backends seamlessly\n",
    "source_ledger = PolarsLedger.load(\"local_experiment.parquet\") \n",
    "target_ledger = DatabaseLedger(\"postgresql://prod-db/experiments\")\n",
    "\n",
    "# Migrate all events to new backend\n",
    "ExperimentMigrator.transfer(source_ledger, target_ledger, experiment_id)\n",
    "```\n",
    "\n",
    "### 3. **Automated Resumption**\n",
    "```python\n",
    "# Production systems can auto-resume experiments on startup\n",
    "class ExperimentOrchestrator:\n",
    "    def resume_all_active_experiments(self):\n",
    "        for experiment_id in self.get_active_experiment_ids():\n",
    "            try:\n",
    "                experiment = self.resume_experiment(experiment_id)\n",
    "                self.schedule_analysis(experiment)\n",
    "                logger.info(f\"Resumed {experiment_id}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to resume {experiment_id}: {e}\")\n",
    "```\n",
    "\n",
    "### 4. **Version Evolution**\n",
    "```python\n",
    "# Handle experiment configuration changes during resumption\n",
    "class ExperimentEvolution:\n",
    "    @staticmethod\n",
    "    def upgrade_config(old_config: dict, target_version: str) -> dict:\n",
    "        # Apply migration rules for configuration changes\n",
    "        if target_version == \"v2.1\":\n",
    "            # Add new guardrail configuration\n",
    "            old_config[\"guardrails\"].append(\n",
    "                GuardrailConfig(\"user_engagement\", alpha=0.01)\n",
    "            )\n",
    "        return old_config\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f190e",
   "metadata": {},
   "source": [
    "## Key Insights: How Easy is Resumption?\n",
    "\n",
    "### âœ… **What Makes Resumption Easy in EarlySign**\n",
    "\n",
    "1. **Event Sourcing Architecture**: \n",
    "   - All state is derived from immutable events\n",
    "   - No hidden state in memory that can be lost\n",
    "   - Complete audit trail for regulatory compliance\n",
    "\n",
    "2. **Ledger as Single Source of Truth**:\n",
    "   - All experiment decisions captured as events\n",
    "   - Statistical computations are reproducible\n",
    "   - No external dependencies for state reconstruction\n",
    "\n",
    "3. **Component-Based Design**:\n",
    "   - Experiments rebuild automatically from configuration\n",
    "   - Internal component state reconstructed from ledger events\n",
    "   - No manual state management required\n",
    "\n",
    "### ðŸ“‹ **Required for Resumption**\n",
    "\n",
    "**Minimal Requirements**:\n",
    "```python\n",
    "# Just 3 things needed for perfect resumption:\n",
    "ledger = PolarsLedger.load(\"experiment.parquet\")      # 1. Persistent ledger\n",
    "config = load_experiment_config(experiment_id)        # 2. Configuration\n",
    "experiment = create_experiment_from_config(config)    # 3. Recreation logic\n",
    "```\n",
    "\n",
    "**The `setup()` call is crucial**:\n",
    "```python  \n",
    "runner = SequentialRunner(experiment, ledger)\n",
    "runner.setup()  # <- This reconstructs all internal state from ledger events!\n",
    "```\n",
    "\n",
    "### ðŸš€ **Production-Ready Features**\n",
    "\n",
    "- **Cross-backend portability**: Move from Polars to Database seamlessly\n",
    "- **Configuration evolution**: Handle parameter changes during resumption  \n",
    "- **Multi-team handoffs**: Complete context preserved for new analysts\n",
    "- **Disaster recovery**: Experiments survive system failures\n",
    "- **Compliance**: Full audit trail maintained across resumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48284a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial 005: Experiment Persistence and Resumption\n",
    "\n",
    "## Overview\n",
    "\n",
    "One of EarlySign's key enterprise features is the ability to **pause and resume experiments** seamlessly. This is crucial for:\n",
    "\n",
    "- **Long-running experiments** that span weeks or months\n",
    "- **System maintenance** or upgrades during experiments\n",
    "- **Regulatory compliance** requiring audit trails\n",
    "- **Disaster recovery** scenarios\n",
    "- **Multi-team handoffs** where different analysts continue experiments\n",
    "\n",
    "This tutorial demonstrates how to:\n",
    "1. **Persist experiment state** in the ledger\n",
    "2. **Resume experiments** from stored data\n",
    "3. **Reconstruct experiment modules** from ledger history\n",
    "4. **Handle configuration changes** during resumption\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Event Sourcing Foundation\n",
    "EarlySign's event sourcing architecture makes persistence natural:\n",
    "- **Immutable events**: All experiment state captured as events\n",
    "- **Complete history**: Every decision and computation recorded\n",
    "- **Reproducible state**: Any point in time can be reconstructed\n",
    "- **Ledger as source of truth**: No external state dependencies\n",
    "\n",
    "### Resumption Patterns\n",
    "```python\n",
    "# Pattern 1: Simple resumption (same configuration)\n",
    "experiment = MyExperiment.from_ledger(ledger, experiment_id)\n",
    "\n",
    "# Pattern 2: Configuration evolution (updated parameters)\n",
    "experiment = MyExperiment.from_ledger(ledger, experiment_id, new_config)\n",
    "\n",
    "# Pattern 3: Cross-platform resumption (different backend)\n",
    "old_ledger = PolarsLedger.load(\"experiment_backup.parquet\")\n",
    "new_ledger = DatabaseLedger(connection_string)\n",
    "experiment = MyExperiment.migrate(old_ledger, new_ledger, experiment_id)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
